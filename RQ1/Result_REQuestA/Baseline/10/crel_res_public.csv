metric,score,evaluation_model,reason,error
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and retrieval context are perfectly aligned, making it a spot-on match!",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a precise answer to the question.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the context discusses unrelated topics like the OPENCOSS platform, evidence management, and safety standards, whereas the input is about an authority",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is directly addressed by the retrieval context, providing a perfect match!",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is asking for a general overview, and the retrieval context perfectly aligns with this request, providing a clear and concise outline of the steps involved in the overall approach.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and retrieval context are perfectly aligned, making it extremely relevant.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a direct and accurate answer to the user",
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the input is asking about flaws in function level requirements, but there is no context provided to relate to the input.",
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the context only provides section headers and page numbers, which are irrelevant to the input question about the survey",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly relevant to the input, and the question is directly answered!",
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the retrieval context is about evidence management in an assurance project, which is unrelated to the input question about business process, indicating only partial relevance.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is a clear and concise question, and there is no retrieval context to compare it with, making it perfectly relevant by default! Well done!",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and retrieval context are perfectly aligned, and the context provides a precise answer to the question.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a seamless connection.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a precise answer to the question.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the context does not provide any information about determining location or percentages, which is the main focus of the input question, as stated in the context ",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and retrieval context are perfectly aligned, making it a perfect match!",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a direct answer to the question.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched with the context, and there",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a seamless connection between the two.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,The score is 1.00 because the input is a unique question that doesn,
Contextual Relevancy,0.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context perfectly aligns with the input, providing a precise definition of the International Rosetta Mission.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input perfectly matches the context, making it a perfect fit!",
Contextual Relevancy,0.0,Llama-3 70B,"The score is 0.00 because the context does not provide specific information about the two asteroids the spacecraft will pass close to, as stated in the reasons for irrelevancy, and only discusses general information about asteroids and comets or unrelated aspects of the spacecraft",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input query, providing a precise and accurate answer to the user",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.3333333333333333,Llama-3 70B,"The score is 0.33 because the context does not mention key concepts like asteroids, planetesimals, or the solar nebula, and instead focuses on unrelated topics like comet composition and spacecraft operations, making it largely irrelevant to the input question.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is a direct question with a clear answer, and there is no retrieval context provided to compare it with, so the relevancy is perfect by default.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly aligned with the retrieval context, and there are no reasons for irrelevancy provided, indicating a seamless connection between the two!",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is directly related to the context, making it perfectly relevant.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is a very specific question about a particular system and the context is empty, indicating a perfect match.",
Contextual Relevancy,0.6666666666666666,Llama-3 70B,"The score is 0.67 because the provided context only contains metadata, lacking any information about what Rosetta is, as stated in the input question.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.0,Llama-3 70B,"The score is 0.00 because there is no relevant information provided in the retrieval context to match the input query, resulting in a complete mismatch.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is clear and concise, and the context is perfectly relevant, providing a direct answer to the question.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context perfectly aligns with the input, providing a precise answer to the question.",
Contextual Relevancy,0.0,Llama-3 70B,The score is 0.00 because there is no relevant information provided to determine the contextual relevancy score.,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and retrieval context are perfectly aligned, with no irrelevant information provided, resulting in a seamless match.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a direct answer to the question asked.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly relevant to the input, providing a precise answer to the question asked.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a seamless connection between the contractor",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly relevant to the input, providing the exact information required.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a direct answer to the question asked.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is directly related to the context, and there are no reasons provided for why it",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context perfectly aligns with the input, providing a direct answer to the question asked.",
Contextual Relevancy,0.0,Llama-3 70B,,
Contextual Relevancy,0.0,Llama-3 70B,The score is 0.00 because there is no provided information to support the relevance of the retrieval context to the input.,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and context are perfectly aligned, with no irrelevant information provided.",
Contextual Relevancy,0.6666666666666666,Llama-3 70B,The score is 0.67 because the context does not mention the key terms ,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly aligned with the context, making it a perfect match!",
Contextual Relevancy,0.0,Llama-3 70B,"The score is 0.00 because there is no relevant context provided to support the input query, making it impossible to determine contextual relevancy.",
Contextual Relevancy,0.5,Llama-3 70B,The score is 0.50 because the retrieval context does not mention Canada,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and context are perfectly aligned, making the context 100% relevant to the input.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because this input perfectly aligns with the context, and there",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is directly answered by the retrieval context, providing a clear and concise response to the user",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and context are perfectly aligned, providing a seamless connection between the question and the relevant information.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and context are perfectly aligned, with no irrelevant information present.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is a question that requires a creative and hypothetical response, and there is no irrelevant context provided.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched with the context, making it a perfect fit!",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is directly addressed in the context, making it perfectly relevant.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a direct and accurate answer to the question.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is highly specific and directly related to the context, making it perfectly relevant.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a precise answer to the question asked.",
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the context is focused on obstacle clearance and rock sizes, which doesn",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched with the retrieval context, making it a perfect match!",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched with the retrieval context, resulting in a perfect alignment of ideas and concepts.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched to the context, with no irrelevant information provided, making it a perfect match.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and retrieval context are perfectly aligned, making it a perfect match!",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and retrieval context are perfectly aligned, with no reasons for irrelevancy provided, indicating a seamless match.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly relevant to the input, with a seamless connection between the two!",
Contextual Relevancy,0.5,Llama-3 70B,The score is 0.50 because there is no relevant information in the retrieval context that answers the question about the spacecraft,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and context are perfectly aligned, and the context fully answers the question posed in the input, providing exactly what the navigation authorities should provide.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly aligned with the context, and there are no reasons provided for why the retrieval context is irrelevant to the input, indicating a seamless match.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a seamless match.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because there is no relevant information provided to support the input query, resulting in a neutral score.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and context are perfectly aligned, providing a seamless connection between the question and the relevant information.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a precise match.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is a clear and concise question, and the retrieval context is not provided, making it impossible to determine irrelevancy.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input directly asks about the steps involved in the approach, and the retrieval context perfectly answers this question, providing a clear and concise response that fully addresses the query.",
Contextual Relevancy,0.6666666666666666,Llama-3 70B,"The score is 0.67 because the context does not provide any information about the person or entity responsible for managing evidence for compliance with safety standards, as stated in the reasons for irrelevancy.",
Contextual Relevancy,1.0,Llama-3 70B,The score is 1.00 because the input is a general question that doesn,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly aligned with the context, and there",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.6666666666666666,Llama-3 70B,The score is 0.67 because the context doesn,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because there is no irrelevant context provided, so the retrieval context is perfectly relevant to the input.",
Contextual Relevancy,0.6666666666666666,Llama-3 70B,The score is 0.67 because the context lacks specific details about the Lunar Exploration Light Rover,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched with the context, making it a perfect fit.",
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the context only discusses speed capabilities on different surfaces, but does not mention the degrees a wheeled vehicle can achieve, which is the main concern of the input question.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a precise answer to the question about the angle of the ramp breakover.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is directly related to the context, making it perfectly relevant.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a precise answer to the question about relative pointing error.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context perfectly aligns with the input, providing a precise answer to the question about absolute measurement error.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a precise and accurate response to the question asked.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched with the context, resulting in a perfect score.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input and retrieval context are perfectly matched, with no irrelevant information present.",
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the context does not provide the relevant information about what will be used to orbit the comet Wirtanen, only discussing mission design, comet environment, and spacecraft",
Contextual Relevancy,0.6666666666666666,Llama-3 70B,"The score is 0.67 because the context does not provide specific information about asteroids passing something, only discussing their general characteristics.",
Contextual Relevancy,0.6666666666666666,Llama-3 70B,"The score is 0.67 because the context is about management and planning, which doesn",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because there are no reasons provided for why the retrieval context is irrelevant to the input, suggesting a perfect match.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly relevant to the input, providing the exact information needed to answer the question about the Rosetta mission and comet Wirtanen.",
Contextual Relevancy,0.0,Llama-3 70B,"The score is 0.00 because the context does not mention asteroids that the spacecraft will pass, making it irrelevant to the input question, as stated in the reasons for irrelevancy.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched with the context, providing a precise answer to the question.",
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the context primarily discusses technical specifications, equations, and test procedures for a flight model, with no mention of fly-by or confidence levels, making it largely unrelated to the input query.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is a specific question about the payload line of sight, and there",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is directly related to the retrieval context, which is not provided, hence the perfect score.",
Contextual Relevancy,0.0,Llama-3 70B,"The score is 0.00 because the context does not mention anything about preventing condensation of propellant or any thermal control capability, which are the key aspects of the input question, making it completely irrelevant.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is a specific question that requires a direct answer, and the retrieval context is perfectly relevant to provide that answer.",
Contextual Relevancy,0.0,Llama-3 70B,"The score is 0.00 because there is no relevant information provided in the context to relate to the input question, leaving the model without any connection to make.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a precise match.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a precise and accurate response to assist RCN Units.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is asking a question that directly matches the context, making it perfectly relevant!",
Contextual Relevancy,0.0,Llama-3 70B,"The score is 0.00 because there is no context provided to determine relevance, resulting in a null correlation between the input and the retrieval context.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.0,Llama-3 70B,"The score is 0.00 because there are no reasons provided for why the retrieval context is irrelevant to the input, indicating a complete mismatch between the two.",
Contextual Relevancy,0.0,Llama-3 70B,"The score is 0.00 because there is no retrieval context provided, making it impossible to determine relevancy.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because there are no reasons provided for why the retrieval context is irrelevant to the input, indicating a perfect match.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is directly addressed in the context, providing a precise answer to the question asked.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched with the context, providing a precise answer to the question about Government Property, which is exactly what the context is about! Well done!",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the context is unrelated to the input, focusing on the Lunar Exploration Light Rover instead of assigned readiness levels and work, as stated in the context.",
Contextual Relevancy,1.0,Llama-3 70B,The score is 1.00 because the input is a specific question about the Contractor,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly matched with the retrieval context, making it a perfect fit!",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is directly related to the context, and there are no reasons for irrelevancy provided, indicating a perfect match.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly aligned with the context, and there are no reasons for irrelevancy provided, indicating a seamless match.",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because this question is perfectly aligned with the retrieval context, and there",
Contextual Relevancy,0.5,Llama-3 70B,"The score is 0.50 because the context does not discuss torques or orthogonal axes, but rather the Lunar Exploration Light Rover, making it only partially relevant to the input question.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a direct answer to the question ",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because there are no reasons for irrelevancy, indicating a perfect match!",
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the input is perfectly clear and well-defined, with no ambiguity or irrelevant information provided, making it easy to understand and respond to.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the context perfectly aligns with the input, providing a precise answer to the question about the subsystem",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context is perfectly aligned with the input, providing a direct answer to the question asked.",
Contextual Relevancy,1.0,Llama-3 70B,"The score is 1.00 because the retrieval context perfectly aligns with the input, providing the exact information requested.",
Contextual Relevancy,0.5,Llama-3 70B,The score is 0.50 because there is no relevant information provided to make a strong connection between the input and the retrieval context.,
Contextual Relevancy,1.0,Llama-3 70B,,
Contextual Relevancy,0.6666666666666666,Llama-3 70B,"The score is 0.67 because the context discusses unrelated topics like spacecraft design and testing, whereas the input is about solar cells, making them unrelated topics, as stated in the reasons for irrelevancy.",
